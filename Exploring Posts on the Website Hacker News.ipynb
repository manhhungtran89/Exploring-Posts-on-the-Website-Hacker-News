{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Posts on the Website Hacker News\n",
    "\n",
    "Hacker News is a popular technology website started by the startup incubator \"Y Combinator\". On this website, users submit their stories, known as \"posts\". These posts are voted and commented upon. Hacker News is very popular technology site and posts belonging to the top of Hacker News' listings can get hundreds of thousands of visitors.\n",
    "\n",
    "In this project, we explore a huge data set with about 300,000 rows contating data of posts on Hacker News. But we reduce to 20,000 rows of a type of interesting posts which receive more comments than the rest. Our goal is to calculate the average number of comments receiving in these posts and more importantly, determine which hours of the day such that the posts created at that hours attract more comments.\n",
    "\n",
    "First of all, we open the data set as list of lists and explore the first 5 rows of this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24'],\n",
       " ['12578997',\n",
       "  'What if we just printed a flatscreen television on the side of our boxes?',\n",
       "  'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43',\n",
       "  '1',\n",
       "  '0',\n",
       "  'pavel_lishin',\n",
       "  '9/26/2016 3:19'],\n",
       " ['12578989',\n",
       "  'algorithmic music',\n",
       "  'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext',\n",
       "  '1',\n",
       "  '0',\n",
       "  'poindontcare',\n",
       "  '9/26/2016 3:16']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from csv import reader\n",
    "open_file=open('hacker_news.csv', encoding ='utf8')\n",
    "read_file=reader(open_file)\n",
    "hn=list(read_file)\n",
    "hn[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to exclude the header in order to analyze our data. In the below we also print the first 5 rows of the data set after exlculing the header. The most important columns for our analysis are 'title', 'num_comments' and 'created_at'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24'],\n",
       " ['12578997',\n",
       "  'What if we just printed a flatscreen television on the side of our boxes?',\n",
       "  'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43',\n",
       "  '1',\n",
       "  '0',\n",
       "  'pavel_lishin',\n",
       "  '9/26/2016 3:19'],\n",
       " ['12578989',\n",
       "  'algorithmic music',\n",
       "  'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext',\n",
       "  '1',\n",
       "  '0',\n",
       "  'poindontcare',\n",
       "  '9/26/2016 3:16'],\n",
       " ['12578979',\n",
       "  'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake',\n",
       "  'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94',\n",
       "  '1',\n",
       "  '0',\n",
       "  'markgainor1',\n",
       "  '9/26/2016 3:14']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header=hn[0]\n",
    "print(header)\n",
    "hn=hn[1:]\n",
    "hn[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our aim is to work with posts having titles starting by 'Ask HN' or 'Show HN' since they receive more comments than the rest. For this reason, we will creat sub-datasets of hn which contain only those titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n",
      "273822\n"
     ]
    }
   ],
   "source": [
    "ask_posts=[]\n",
    "show_posts=[]\n",
    "other_posts=[]\n",
    "for row in hn:\n",
    "    title=row[1]# title column\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have thus created sub lists of our data set. More precisely, the number of posts starting with 'ask hn' is 9139 and the number of posts starting with 'show hn' is 10158. Let us print the first few rows of these two new lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53'], ['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17'], ['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57'], ['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48'], ['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']]\n",
      "\n",
      "\n",
      "[['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36'], ['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01'], ['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44'], ['12577991', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'https://github.com/jakebian/zeal', '2', '0', 'dbranes', '9/25/2016 23:17'], ['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']]\n"
     ]
    }
   ],
   "source": [
    "print(ask_posts[0:5])\n",
    "print('\\n')\n",
    "print(show_posts[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to check if ask posts or show posts receive more comments. We calculate the average number of comments receiving by those posts. To do this, we calculate the total number of comments receiving by those posts and then divide to the total number of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.393478498741656\n",
      "4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments=0\n",
    "for row in ask_posts:\n",
    "    num_comments=int(row[4]) # comments column\n",
    "    total_ask_comments+=num_comments\n",
    "avg_ask_comments=total_ask_comments/len(ask_posts)\n",
    "print(avg_ask_comments)\n",
    "\n",
    "total_show_comments=0\n",
    "for row in show_posts:\n",
    "    num_comments=int(row[4]) # comments column\n",
    "    total_show_comments+=num_comments\n",
    "avg_show_comments=total_show_comments/len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that on average, ask posts receive more comments than show posts. It would be more interesting to analyze ask posts only. \n",
    "\n",
    "The goal is to check which created time is more likely to attract more comments. To do this, we calculate the average the number of comments received by ask posts in each hour of the day. For convenience, we import the module datetime to work with date and time objects in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02': 269, '01': 282, '22': 383, '21': 518, '19': 552, '17': 587, '15': 646, '14': 513, '13': 444, '11': 312, '10': 282, '09': 222, '07': 226, '03': 271, '23': 343, '20': 510, '16': 579, '08': 257, '00': 301, '18': 614, '12': 342, '04': 243, '06': 234, '05': 209}\n",
      "\n",
      "\n",
      "{'02': 2996, '01': 2089, '22': 3372, '21': 4500, '19': 3954, '17': 5547, '15': 18525, '14': 4972, '13': 7245, '11': 2797, '10': 3013, '09': 1477, '07': 1585, '03': 2154, '23': 2297, '20': 4462, '16': 4466, '08': 2362, '00': 2277, '18': 4877, '12': 4234, '04': 2360, '06': 1587, '05': 1838}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# Creat list of lists, each list consists of a time and the number of comments created at that time.\n",
    "result_list=[]\n",
    "for row in ask_posts:\n",
    "    created_at=row[6] # created time of a post column\n",
    "    num_comments=int(row[4])\n",
    "    add_list=[created_at, num_comments]\n",
    "    result_list.append(add_list)\n",
    "\n",
    "# Total number of posts and comments at a certain time.   \n",
    "counts_by_hour={}\n",
    "comments_by_hour={}\n",
    "for row in result_list:\n",
    "    date_time=row[0]\n",
    "    num_comments=row[1]\n",
    "    date_time_object = dt.datetime.strptime(date_time, \"%m/%d/%Y %H:%M\")\n",
    "    hour = dt.datetime.strftime(date_time_object, \"%H\")\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour]=1\n",
    "        comments_by_hour[hour]=num_comments\n",
    "    else:\n",
    "        counts_by_hour[hour]+=1\n",
    "        comments_by_hour[hour]+=num_comments\n",
    "print(counts_by_hour)        \n",
    "print('\\n')\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these two dictionaties, we are able to calculate the average number of comments of posts which are created at a certain time of the day. We obtain lists of lists by the following program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['02', 11.137546468401487], ['01', 7.407801418439717], ['22', 8.804177545691905], ['21', 8.687258687258687], ['19', 7.163043478260869], ['17', 9.449744463373083], ['15', 28.676470588235293], ['14', 9.692007797270955], ['13', 16.31756756756757], ['11', 8.96474358974359], ['10', 10.684397163120567], ['09', 6.653153153153153], ['07', 7.013274336283186], ['03', 7.948339483394834], ['23', 6.696793002915452], ['20', 8.749019607843136], ['16', 7.713298791018998], ['08', 9.190661478599221], ['00', 7.5647840531561465], ['18', 7.94299674267101], ['12', 12.380116959064328], ['04', 9.7119341563786], ['06', 6.782051282051282], ['05', 8.794258373205741]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour=[]\n",
    "for hour in counts_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "print(avg_by_hour)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have obtained the average number of comments for ask posts at certain time. But the result seems to be difficult to read. To solve this problem, we re-arrange this result by the descending order. One need to swap the columns in order to use the sorted function in descending order. The reason is because in each list of the above list of lists avg_by_hour, the first element is time while we want to look for the highest number of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.137546468401487, '02'], [7.407801418439717, '01'], [8.804177545691905, '22'], [8.687258687258687, '21'], [7.163043478260869, '19'], [9.449744463373083, '17'], [28.676470588235293, '15'], [9.692007797270955, '14'], [16.31756756756757, '13'], [8.96474358974359, '11'], [10.684397163120567, '10'], [6.653153153153153, '09'], [7.013274336283186, '07'], [7.948339483394834, '03'], [6.696793002915452, '23'], [8.749019607843136, '20'], [7.713298791018998, '16'], [9.190661478599221, '08'], [7.5647840531561465, '00'], [7.94299674267101, '18'], [12.380116959064328, '12'], [9.7119341563786, '04'], [6.782051282051282, '06'], [8.794258373205741, '05']]\n",
      "\n",
      "\n",
      "Top 5 Hours for Ask Posts Comments:\n",
      "[[28.676470588235293, '15'], [16.31756756756757, '13'], [12.380116959064328, '12'], [11.137546468401487, '02'], [10.684397163120567, '10']]\n",
      "\n",
      "\n",
      "15:00: 28.68 average comments per post\n",
      "13:00: 16.32 average comments per post\n",
      "12:00: 12.38 average comments per post\n",
      "02:00: 11.14 average comments per post\n",
      "10:00: 10.68 average comments per post\n"
     ]
    }
   ],
   "source": [
    "\n",
    "swap_avg_by_hour=[]\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "print(swap_avg_by_hour)\n",
    "print('\\n')\n",
    "\n",
    "sorted_wap=sorted(swap_avg_by_hour, reverse = True)\n",
    "print('Top 5 Hours for Ask Posts Comments:')\n",
    "print(sorted_wap[0:5])\n",
    "print('\\n')\n",
    "for row in sorted_wap[0:5]:\n",
    "    avg=row[0]\n",
    "    hour=row[1]\n",
    "    hour_object=dt.datetime.strptime(hour, '%H')\n",
    "    hour_format=dt.datetime.strftime(hour_object, '%H:%M')\n",
    "    result='{}: {:.2f} average comments per post'.format(hour_format, avg)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have conclude that to get a chance of receiving more commments, one should creat a post at 15:00, 13:00, 12:00, 02:00 or 10:00. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "In this project, we have explored the data set of posts on the website Hacker News. Our conclusion is that the posts staring with 'Ask HN' attract more comments. Moreover, by calculating the average number of comments of those posts at a certain time, we conclude that to get a chance of receiving more commments, one should creat a post at 15:00, 13:00, 12:00, 02:00 or 10:00. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
